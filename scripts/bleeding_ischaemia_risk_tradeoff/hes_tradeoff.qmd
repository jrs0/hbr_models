---
title: "Bleeding/Ischaemia Risk Trade-off Models"
project:
  output-dir: _output
execute:
  echo: false
  warning: false
format:
  pdf:
    keep-tex: true
jupyter: python3
engine: jupyter
fig-format: png
bibliography: references.bib
csl: citation_style.csl
geometry:
  - top=30mm
  - left=20mm
  - heightrounded
---

```{python}
# Some tips on using this file
# - print() does not work for rendering markdown in code block. It will mess up
#   the order of figures and text (e.g. headings)
# - To make heading, using display(Markdown("\nHeading Name")). The newline is
#   important, and I coulnd't figure out any other way other than \n to add it.
# - In order to use inline variables like `{python} variable`, you need at least 
#   quarto 1.4. You can get the prerelease from here: https://quarto.org/docs/download/prerelease
#   (it doesn't require admin rights).
#   

import os

os.chdir("../prototypes")

import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

import save_datasets as ds
from stability import plot_instability
from calibration import (
    get_bootstrapped_calibration,
    plot_calibration_curves,
    plot_prediction_distribution,
)
from summarise_model import get_model_summary, plot_model_validation_2page
from roc import get_bootstrapped_roc, get_bootstrapped_auc, plot_roc_curves

dataset_name = {
    "manual_codes": "HES (manual code groups)",
    "all_codes": "HES (all codes)",
    "manual_codes_swd": "HES (manual code groups) + SWD",
}
model_names = {
    "simple_logistic_regression": "Logistic Regression",
    "truncsvd_logistic_regression": "Truncated SVD + Logistic Regression",
}
outcome_names = {
    "bleeding_al_ani_outcome": "Bleeding",
    "hussain_ami_stroke_outcome": "AMI or Stroke",
}

# The generated report relates to one dataset. Pick that dataset here.
dataset = "manual_codes"
dataset_title = dataset_name["manual_codes"]
```

# Summary

```{python}
# Load any model to find which dataset was used (the script assumes that the same dataset
# was used to fit all models)
example_model_info = ds.load_fit_info(f"{dataset}_{list(model_names)[0]}_{list(outcome_names)[0]}")
dataset_path = example_model_info["dataset_path"]
dataset = pd.read_pickle(dataset_path)
num_rows = dataset.shape[0]
start_date = dataset.idx_date.min().date().isoformat()
end_date = dataset.idx_date.max().date().isoformat()
```

This document contains the results of models for bleeding and ischaemia risk in heart attack patients, developed using the `{python} dataset_title` dataset. Table 1 shows a summary of the performance of the models for bleeding and ischaemia across all models and datasets. 

The dataset contains `{python} num_rows` index events, defined as acute coronary syndromes (ACS) or percutaneous coronary intervention (PCI) procedures. The ACS definition has been validated to achieve at least 70% positive predictive value for identifying all myocardial infarction (MI), and distinguishing ST-segment elevation MI from non-ST-segment MI [@biobankdefinitions]. Index events span a date range from `{python} start_date` to `{python} end_date`.

Models for bleeding are trained using an outcome defintion that has been verified to identify major bleeding with positive predicted value (PPV) of 88%[@al2015identifying]. Ischaemia models are trained on a 2-point major adverse cardiac (MACE) definition including acute myocardial infarction and stroke [@hussain2018association], chosen because the components have been validated in administrative databases [@juurlink2006canadian; @kokotailo2005coding].

```{python}
#| label: tbl-summary
#| tbl-cap: 'Summary of model performance for bleeding and ischaemia'
#| tbl-column: body
#| output: asis

all_model_summary = []
for model, model_title in model_names.items():
  for outcome, outcome_title in outcome_names.items():
    try:
      df = get_model_summary(dataset, model, outcome)
      df.insert(0, "Model", model_title)
      df.insert(0, "Outcome", outcome_title)
      all_model_summary.append(df)
    except:
      # Failed to get summary for mobel (might not exist on disk)
      pass

try:
  summary = pd.concat(all_model_summary)
  print(
      summary.to_latex(
          index = False,
          position = 'h',
          caption = f"{dataset_title}",
          float_format="%.2f",
      )
  )
except:
  # This may happen if there is not table associated with the
  # dataset (not on disk)
  pass
```


# Introduction


 
# Literature



{{< pagebreak >}}
# Models

```{python}
#| output: asis

# Page break before the first model section
#display(Markdown("{{< pagebreak >}}"))

  
# This is the place to put exactly one page summarising
# the dataset characteristics
display(Markdown("Dataset description here.\\"))

num_models = len(model_names)
for m, (model, model_title) in enumerate(model_names.items()):
  display(Markdown("{{< pagebreak >}}"))
  display(Markdown(f"\n## {model_title}"))
  for outcome, outcome_title in outcome_names.items():
    #display(Markdown("{{< pagebreak >}}"))
    display(Markdown(f"\n### {outcome_title}"))
    try:
      plot_model_validation_2page(dataset, model, outcome)
    except:
      #display(Markdown("{{< pagebreak >}}"))
      display(Markdown("Currently missing.\\"))
```

## Risk Trade-off Model

# Discussion

# Conclusion